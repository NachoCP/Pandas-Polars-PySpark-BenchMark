{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory /Users/NachoCorcuera/PycharmProjects/Pandas-Polars-PySpark-BenchMark/notebooks\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Start timer\n",
    "\n",
    "# get current directory\n",
    "path = os.getcwd()\n",
    "print(\"Current Directory\", path)\n",
    " \n",
    "# prints parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(path, os.pardir))\n",
    "input_dir = f\"{parent_dir}/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def join_df():\n",
    "    regions = [\n",
    "        \"Europe\", \n",
    "        \"North America\", \n",
    "        \"Asia\", \n",
    "        \"Sub-Saharan Africa\", \n",
    "        \"Central America and the Caribbean\", \n",
    "        \"Middle East and North Africa\", \n",
    "        \"Australia and Oceania\"\n",
    "    ]\n",
    "\n",
    "    aliases = [\n",
    "        \"EU\", \n",
    "        \"NA\", \n",
    "        \"AS\", \n",
    "        \"SSA\", \n",
    "        \"CA\", \n",
    "        \"MENA\", \n",
    "        \"AUS\"\n",
    "    ]\n",
    "\n",
    "    # Create the DataFrame using Pandas\n",
    "    df_regions = pd.DataFrame({\n",
    "        \"Region\": regions,\n",
    "        \"Alias\": aliases\n",
    "    })\n",
    "\n",
    "    # Display the DataFrame to verify its contents\n",
    "    return df_regions\n",
    "\n",
    "def processing_df(file):\n",
    "    times = {}\n",
    "    start_time_full = time.time()\n",
    "\n",
    "    # Reading time\n",
    "    df = pd.read_csv(f\"{input_dir}/{file}.csv\")\n",
    "    end_time = time.time()\n",
    "    times[\"read_csv\"] = end_time - start_time_full\n",
    "\n",
    "    # Filtering time\n",
    "    start_time = time.time()\n",
    "    filtered_pandas = df[df['Total Profit'] > 2000]\n",
    "    end_time = time.time()\n",
    "    times[\"filter\"] = end_time - start_time\n",
    "\n",
    "    # Aggregation\n",
    "    start_time = time.time()\n",
    "    aggregated_pandas = df.groupby('Region').agg(\n",
    "        sales=('Total Profit', 'sum'),\n",
    "        sales_mean=('Total Profit', 'mean'),\n",
    "        sales_max=('Total Profit', 'max'),\n",
    "        sales_min=('Total Profit', 'min'),\n",
    "        sales_median=('Total Profit', 'median')\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    times[\"aggregation\"] = end_time - start_time\n",
    "\n",
    "    # Joining time\n",
    "    start_time = time.time()\n",
    "    df_regions = join_df()  # Assuming join_df returns a DataFrame to join\n",
    "    df_joined = df.merge(df_regions, on=\"Region\", how=\"left\")\n",
    "    end_time = time.time()\n",
    "    times[\"join\"] = end_time - start_time\n",
    "\n",
    "    # Writing time\n",
    "    start_time = time.time()\n",
    "    df_joined.to_csv(\"testing_write_2.csv\", index=False)\n",
    "    end_time = time.time()\n",
    "    times[\"write\"] = end_time - start_time\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"sales_50000\",\n",
    "             \"sales_250000\",\n",
    "             \"sales_1000000\",\n",
    "             \"sales_5000000\",\n",
    "             \"sales_25000000\"]\n",
    "\n",
    "\n",
    "times = {file: processing_df(file) for file in file_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sales_50000': {'read_csv': 0.060051918029785156,\n",
       "  'filter': 0.004604339599609375,\n",
       "  'aggregation': 0.009542226791381836,\n",
       "  'join': 0.006765127182006836,\n",
       "  'write': 0.28705716133117676},\n",
       " 'sales_250000': {'read_csv': 0.2204129695892334,\n",
       "  'filter': 0.011040687561035156,\n",
       "  'aggregation': 0.01796126365661621,\n",
       "  'join': 0.02841019630432129,\n",
       "  'write': 0.9712498188018799},\n",
       " 'sales_1000000': {'read_csv': 0.8394689559936523,\n",
       "  'filter': 0.05398988723754883,\n",
       "  'aggregation': 0.06402993202209473,\n",
       "  'join': 0.11523294448852539,\n",
       "  'write': 3.826240062713623},\n",
       " 'sales_5000000': {'read_csv': 4.053663969039917,\n",
       "  'filter': 0.24633097648620605,\n",
       "  'aggregation': 0.30512070655822754,\n",
       "  'join': 0.5451042652130127,\n",
       "  'write': 19.169981956481934},\n",
       " 'sales_25000000': {'read_csv': 27.962117195129395,\n",
       "  'filter': 2.4532999992370605,\n",
       "  'aggregation': 2.1596198081970215,\n",
       "  'join': 3.90976619720459,\n",
       "  'write': 151.89875292778015}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def processing_parquet_df(file):\n",
    "    times = {}\n",
    "    start_time_full = time.time()\n",
    "\n",
    "    # Reading time\n",
    "    data_dir = Path(f\"{input_dir}/{file}\")\n",
    "\n",
    "    df = pd.concat(\n",
    "    pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "    for parquet_file in data_dir.glob('*.parquet')\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    times[\"read_csv\"] = end_time - start_time_full\n",
    "\n",
    "    # Filtering time\n",
    "    start_time = time.time()\n",
    "    filtered_pandas = df[df['Total Profit'] > 2000]\n",
    "    end_time = time.time()\n",
    "    times[\"filter\"] = end_time - start_time\n",
    "\n",
    "    # Aggregation\n",
    "    start_time = time.time()\n",
    "    aggregated_pandas = df.groupby('Region').agg(\n",
    "        sales=('Total Profit', 'sum'),\n",
    "        sales_mean=('Total Profit', 'mean'),\n",
    "        sales_max=('Total Profit', 'max'),\n",
    "        sales_min=('Total Profit', 'min'),\n",
    "        sales_median=('Total Profit', 'median')\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    times[\"aggregation\"] = end_time - start_time\n",
    "\n",
    "    # Joining time\n",
    "    start_time = time.time()\n",
    "    df_regions = join_df()  # Assuming join_df returns a DataFrame to join\n",
    "    df_joined = df.merge(df_regions, on=\"Region\", how=\"left\")\n",
    "    end_time = time.time()\n",
    "    times[\"join\"] = end_time - start_time\n",
    "\n",
    "    # Writing time\n",
    "    start_time = time.time()\n",
    "    df_joined.to_parquet(\"testing_write_3.parquet\", index=False)\n",
    "    end_time = time.time()\n",
    "    times[\"write\"] = end_time - start_time\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'read_csv': 5.053792953491211,\n",
       " 'filter': 1.944251298904419,\n",
       " 'aggregation': 1.9538791179656982,\n",
       " 'join': 5.851027965545654,\n",
       " 'write': 15.206745147705078}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"parquet/sales_25000000\"\n",
    "processing_parquet_df(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(file)\n",
    "for parquet_file in data_dir.glob('*.parquet'):\n",
    "    print(parquet_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
