{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory /Users/NachoCorcuera/PycharmProjects/Pandas-Polars-PySpark-BenchMark/notebooks\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    " \n",
    "import os\n",
    "\n",
    "\n",
    "# Start timer\n",
    "\n",
    "# get current directory\n",
    "path = os.getcwd()\n",
    "print(\"Current Directory\", path)\n",
    " \n",
    "# prints parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(path, os.pardir))\n",
    "input_dir = f\"{parent_dir}/data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars Eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def join_df():\n",
    "    regions = [\n",
    "        \"Europe\", \n",
    "        \"North America\", \n",
    "        \"Asia\", \n",
    "        \"Sub-Saharan Africa\", \n",
    "        \"Central America and the Caribbean\", \n",
    "        \"Middle East and North Africa\", \n",
    "        \"Australia and Oceania\"\n",
    "    ]\n",
    "\n",
    "    aliases = [\n",
    "        \"EU\", \n",
    "        \"NA\", \n",
    "        \"AS\", \n",
    "        \"SSA\", \n",
    "        \"CA\", \n",
    "        \"MENA\", \n",
    "        \"AUS\"\n",
    "    ]\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df_regions = pl.DataFrame({\n",
    "        \"Region\": regions,\n",
    "        \"Alias\": aliases\n",
    "    })\n",
    "\n",
    "    # Display the DataFrame to verify its contents\n",
    "    return df_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def processing_df(file):\n",
    "    times = {}\n",
    "    start_time_full = time.time()\n",
    "\n",
    "    ## Reading time\n",
    "    df = pl.read_csv(f\"{input_dir}/{file}.csv\")\n",
    "    end_time = time.time()\n",
    "    times[\"read_csv\"] = end_time - start_time_full\n",
    "\n",
    "    ## Filtering time\n",
    "    start_time = time.time()\n",
    "    filtered_polars = df.filter(pl.col('Total Profit') > 2000)\n",
    "    end_time = time.time()\n",
    "    times[\"filter\"] = end_time - start_time\n",
    "\n",
    "    ## Aggregation\n",
    "    start_time = time.time()\n",
    "    df.group_by('Region').agg(pl.col('Total Profit').sum().alias('sales'),\n",
    "                            pl.col('Total Profit').mean().alias('sales_mean'),\n",
    "                            pl.col('Total Profit').max().alias('sales_max'),\n",
    "                            pl.col('Total Profit').min().alias('sales_min'),\n",
    "                            pl.col('Total Profit').median().alias('sales_median'))\n",
    "    end_time = time.time()\n",
    "    times[\"aggregation\"] = end_time - start_time\n",
    "\n",
    "\n",
    "    ## Joining time\n",
    "    start_time = time.time()\n",
    "    df_regions = join_df()\n",
    "    df_joined = df.join(df_regions, on=\"Region\", how=\"left\")\n",
    "    end_time = time.time()\n",
    "    times[\"join\"] = end_time - start_time\n",
    "\n",
    "\n",
    "    ## Writting time\n",
    "    start_time = time.time()\n",
    "    df_regions = join_df()\n",
    "    df_joined.write_csv(\"testing_write_2.csv\")\n",
    "    end_time = time.time()\n",
    "    times[\"write\"] = end_time - start_time\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"sales_50000\",\n",
    "             \"sales_250000\",\n",
    "             \"sales_1000000\",\n",
    "             \"sales_5000000\",\n",
    "             \"sales_25000000\"]\n",
    "\n",
    "\n",
    "times = {file: processing_df(file) for file in file_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sales_50000': {'read_csv': 0.040792226791381836,\n",
       "  'filter': 0.0022542476654052734,\n",
       "  'aggregation': 0.0019421577453613281,\n",
       "  'join': 0.0011718273162841797,\n",
       "  'write': 0.08605599403381348},\n",
       " 'sales_250000': {'read_csv': 0.02921295166015625,\n",
       "  'filter': 0.0054209232330322266,\n",
       "  'aggregation': 0.006804943084716797,\n",
       "  'join': 0.0028297901153564453,\n",
       "  'write': 0.051733970642089844},\n",
       " 'sales_1000000': {'read_csv': 0.0826117992401123,\n",
       "  'filter': 0.019051790237426758,\n",
       "  'aggregation': 0.03006911277770996,\n",
       "  'join': 0.011890888214111328,\n",
       "  'write': 0.1584300994873047},\n",
       " 'sales_5000000': {'read_csv': 0.43853116035461426,\n",
       "  'filter': 0.08569121360778809,\n",
       "  'aggregation': 0.15650582313537598,\n",
       "  'join': 0.056740760803222656,\n",
       "  'write': 0.8676810264587402},\n",
       " 'sales_25000000': {'read_csv': 2.2471492290496826,\n",
       "  'filter': 3.014470100402832,\n",
       "  'aggregation': 2.2853622436523438,\n",
       "  'join': 0.3383932113647461,\n",
       "  'write': 5.165363073348999}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def processing_df_parquet(file):\n",
    "    times = {}\n",
    "    start_time_full = time.time()\n",
    "\n",
    "    ## Reading time\n",
    "    df = pl.read_parquet(f\"{input_dir}/{file}/*.parquet\")\n",
    "    end_time = time.time()\n",
    "    times[\"read_csv\"] = end_time - start_time_full\n",
    "\n",
    "    ## Filtering time\n",
    "    start_time = time.time()\n",
    "    filtered_polars = df.filter(pl.col('Total Profit') > 2000)\n",
    "    end_time = time.time()\n",
    "    times[\"filter\"] = end_time - start_time\n",
    "\n",
    "    ## Aggregation\n",
    "    start_time = time.time()\n",
    "    df.group_by('Region').agg(pl.col('Total Profit').sum().alias('sales'),\n",
    "                            pl.col('Total Profit').mean().alias('sales_mean'),\n",
    "                            pl.col('Total Profit').max().alias('sales_max'),\n",
    "                            pl.col('Total Profit').min().alias('sales_min'),\n",
    "                            pl.col('Total Profit').median().alias('sales_median'))\n",
    "    end_time = time.time()\n",
    "    times[\"aggregation\"] = end_time - start_time\n",
    "\n",
    "\n",
    "    ## Joining time\n",
    "    start_time = time.time()\n",
    "    df_regions = join_df()\n",
    "    df_joined = df.join(df_regions, on=\"Region\", how=\"left\")\n",
    "    end_time = time.time()\n",
    "    times[\"join\"] = end_time - start_time\n",
    "\n",
    "\n",
    "    ## Writting time\n",
    "    start_time = time.time()\n",
    "    df_regions = join_df()\n",
    "    df_joined.write_parquet(\"testing_write_2\")\n",
    "    end_time = time.time()\n",
    "    times[\"write\"] = end_time - start_time\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'read_csv': 3.8856701850891113,\n",
       " 'filter': 1.0167460441589355,\n",
       " 'aggregation': 0.48287105560302734,\n",
       " 'join': 0.4307827949523926,\n",
       " 'write': 21.223906755447388}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"parquet/sales_25000000\"\n",
    "processing_df_parquet(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
